{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EE 769 Project: Object Detection using Faster R-CNN\n",
        "\n",
        "Students: *Kasi Reddy Sreeman Reddy* (190070029), *Jahnavi Devangula* (20d070025) and *Kshitiz Susawat* (19D070030)\n",
        "\n",
        "In this project we demonstrate how to use TensorFlow to perform object detection on images. It involves building a deep learning model based on the Faster R-CNN architecture and training it on the Pascal VOC dataset. The trained model is then used to make predictions on new images and mark the detected objects with bounding boxes and class labels. The project provides a step-by-step guide on how to prepare the dataset, train the model, and use it for object detection on new images.\n",
        "\n",
        "Dataset links:\n",
        "- http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "- http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
        "\n",
        "**Note**: Originally our project was \"Oriented R-CNN for Object Detection\" but due to lack of time we did a simpler one."
      ],
      "metadata": {
        "id": "AA9lXHjBNhPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "!tar -xf VOCtrainval_06-Nov-2007.tar\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
        "!tar -xf VOCtest_06-Nov-2007.tar\n",
        "\n",
        "# Constants\n",
        "VOC_DIR = \"VOCdevkit/VOC2007\"\n",
        "IMAGE_DIR = os.path.join(VOC_DIR, \"JPEGImages\")\n",
        "ANNOTATION_DIR = os.path.join(VOC_DIR, \"Annotations\")\n",
        "IMAGE_SETS_DIR = os.path.join(VOC_DIR, \"ImageSets/Main\")\n",
        "CLASSES = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
        "           \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
        "           \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rJfHo4YNcaO",
        "outputId": "785d3aad-560f-47b5-a27c-4d12ed2428f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-29 18:20:48--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460032000 (439M) [application/x-tar]\n",
            "Saving to: ‘VOCtrainval_06-Nov-2007.tar.5’\n",
            "\n",
            "VOCtrainval_06-Nov- 100%[===================>] 438.72M  30.9MB/s    in 22s     \n",
            "\n",
            "2023-04-29 18:21:10 (20.2 MB/s) - ‘VOCtrainval_06-Nov-2007.tar.5’ saved [460032000/460032000]\n",
            "\n",
            "--2023-04-29 18:21:15--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 451020800 (430M) [application/x-tar]\n",
            "Saving to: ‘VOCtest_06-Nov-2007.tar.4’\n",
            "\n",
            "VOCtest_06-Nov-2007 100%[===================>] 430.13M  30.9MB/s    in 19s     \n",
            "\n",
            "2023-04-29 18:21:35 (22.5 MB/s) - ‘VOCtest_06-Nov-2007.tar.4’ saved [451020800/451020800]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(split):\n",
        "    assert split in [\"trainval\", \"test\"], f\"Invalid split: {split}\"\n",
        "\n",
        "    # Define paths to image and annotation directories\n",
        "    image_dir = f\"VOCdevkit/VOC2007{split}/JPEGImages\"\n",
        "    annotation_dir = f\"VOCdevkit/VOC2007{split}/Annotations\"\n",
        "\n",
        "    # Get list of image and annotation filenames\n",
        "    image_filenames = sorted(os.listdir(image_dir))\n",
        "    annotation_filenames = sorted(os.listdir(annotation_dir))\n",
        "\n",
        "    # Get full paths to images and annotations\n",
        "    image_paths = [os.path.join(image_dir, filename) for filename in image_filenames]\n",
        "    annotation_paths = [os.path.join(annotation_dir, filename) for filename in annotation_filenames]\n",
        "\n",
        "    return image_paths, annotation_paths\n"
      ],
      "metadata": {
        "id": "TWUVH_6gBJRb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(image, annotation):\n",
        "    # Convert the image to a tensor\n",
        "    image_tensor = tf.convert_to_tensor(image)\n",
        "    image_tensor = tf.image.convert_image_dtype(image_tensor, tf.float32)\n",
        "    image_tensor = tf.image.resize(image_tensor, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    \n",
        "    # Get the bounding boxes and labels from the annotations\n",
        "    boxes = [ann[\"bbox\"] for ann in annotation]\n",
        "    labels = [ann[\"label\"] for ann in annotation]\n",
        "    \n",
        "    # Convert the boxes and labels to tensors\n",
        "    box_tensors = [tf.convert_to_tensor(box) for box in boxes]\n",
        "    label_tensors = [tf.convert_to_tensor(label) for label in labels]\n",
        "    \n",
        "    # Convert the tensors to a dictionary\n",
        "    target = {\"bbox\": tf.stack(box_tensors), \"label\": tf.stack(label_tensors)}\n",
        "    \n",
        "    return image_tensor, target\n"
      ],
      "metadata": {
        "id": "kNv0KFzrBLWo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    # Load pre-trained VGG-16 model\n",
        "    base_model = tf.keras.applications.VGG16(include_top=False, weights=\"imagenet\")\n",
        "\n",
        "    # Create Fast R-CNN model\n",
        "    inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    x = tf.keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    box_outputs = tf.keras.layers.Dense(NUM_CLASSES * 4, activation=\"linear\")(x)\n",
        "    label_outputs = tf.keras.layers.Dense(NUM_CLASSES + 1, activation=\"softmax\")(x)\n",
        "    outputs = tf.keras.layers.Concatenate()([box_outputs, label_outputs])\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "r_CzCbugBN3T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_images, train_boxes, train_labels, val_images, val_boxes, val_labels):\n",
        "    # Create optimizer and loss function\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
        "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        x=train_images,\n",
        "        y={\"box_outputs\": train_boxes, \"label_outputs\": train_labels},\n",
        "        validation_data=(val_images, {\"box_outputs\": val_boxes, \"label_outputs\": val_labels}),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=10,\n",
        "    )\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "QQwWRCbkBWn6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Read data\n",
        "    train_images, train_annotations = read_data(\"trainval\")\n",
        "    val_images, val_annotations = read_data(\"test\")\n",
        "\n",
        "    # Set hyperparameters\n",
        "    NUM_CLASSES = 20 # The PASCAL VOC 2007 dataset has 20 object classes\n",
        "    BATCH_SIZE = 16  # You can set this to a suitable value based on your available memory and GPU resources\n",
        "\n",
        "    # Preprocess data\n",
        "    train_images, train_boxes, train_labels = preprocess_data(train_images, train_annotations)\n",
        "    val_images, val_boxes, val_labels = preprocess_data(val_images, val_annotations)\n",
        "\n",
        "    # Create model\n",
        "    model = create_model(NUM_CLASSES)\n",
        "\n",
        "    # Load the weights\n",
        "    model.load_weights(weights_path)\n",
        "\n",
        "    # Make predictions on the images\n",
        "    predictions = model.predict(images)\n",
        "\n",
        "    # Train model\n",
        "    history = train_model(model, train_images, train_boxes, train_labels, val_images, val_boxes, val_labels, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Plot training history\n",
        "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2pTe-0PoBY84"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_annotations(annotation_path):\n",
        "    tree = ET.parse(annotation_path)\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    boxes = []\n",
        "    classes = []\n",
        "    \n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        xmin = int(obj.find('bndbox/xmin').text)\n",
        "        ymin = int(obj.find('bndbox/ymin').text)\n",
        "        xmax = int(obj.find('bndbox/xmax').text)\n",
        "        ymax = int(obj.find('bndbox/ymax').text)\n",
        "        boxes.append([xmin, ymin, xmax, ymax])\n",
        "        classes.append(class_name)\n",
        "        \n",
        "    return boxes, classes\n",
        "\n",
        "\n",
        "# Define the path to the annotations file\n",
        "annotation_path = 'VOCdevkit/VOC2007/Annotations'\n",
        "\n",
        "# Load the annotations for each image\n",
        "annotations = [load_annotations(os.path.join(annotation_path, f'{os.path.splitext(os.path.basename(path))[0]}.xml')) for path in image_paths]\n",
        "\n",
        "# Load and preprocess each image\n",
        "images = [preprocess_data(cv2.imread(path), annot) for path, annot in zip(image_paths, annotations)]\n",
        "\n",
        "# Make predictions on the images\n",
        "predictions = model.predict(images)\n",
        "\n",
        "# Process the predictions\n",
        "boxes, classes = process_predictions(predictions, confidence_threshold=0.5, overlap_threshold=0.5)\n",
        "\n",
        "# Display each image with the detected objects marked\n",
        "for path, box, cls in zip(image_paths, boxes, classes):\n",
        "    display_image_with_boxes(path, box, cls)\n"
      ],
      "metadata": {
        "id": "KNAgkIH1MA2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image_with_boxes(image_path, boxes, classes):\n",
        "    # Load image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Create figure and axes\n",
        "    fig, ax = plt.subplots(1)\n",
        "    \n",
        "    # Display the image\n",
        "    ax.imshow(img)\n",
        "    \n",
        "    # Plot each bounding box and class label\n",
        "    for box, cls in zip(boxes, classes):\n",
        "        x1, y1, x2, y2 = box\n",
        "        w, h = x2 - x1, y2 - y1\n",
        "        color = np.random.uniform(0, 1, size=3)\n",
        "        \n",
        "        # Add bounding box\n",
        "        rect = plt.Rectangle((x1, y1), w, h, fill=False, linewidth=2.5, edgecolor=color)\n",
        "        ax.add_patch(rect)\n",
        "        \n",
        "        # Add class label\n",
        "        text = f\"{cls}\"\n",
        "        ax.text(x1, y1, text, fontsize=10, bbox=dict(facecolor=color, alpha=0.5))\n",
        "    \n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Define paths to some sample images\n",
        "image_paths = [\"VOCdevkit/VOC2007/JPEGImages/000001.jpg\",\n",
        "               \"VOCdevkit/VOC2007/JPEGImages/000002.jpg\",\n",
        "               \"VOCdevkit/VOC2007/JPEGImages/000003.jpg\",\n",
        "               \"VOCdevkit/VOC2007/JPEGImages/000004.jpg\",\n",
        "               \"VOCdevkit/VOC2007/JPEGImages/000005.jpg\"]\n",
        "\n",
        "# Load and preprocess each image\n",
        "images = [preprocess_data(cv2.imread(path), annotations) for path in image_paths]\n",
        "\n",
        "# Make predictions on the images\n",
        "predictions = model.predict(images)\n",
        "\n",
        "# Convert the predictions into human-readable labels\n",
        "boxes, scores, classes = convert_predictions(predictions, ANCHORS, \n",
        "                                             NUM_CLASSES, \n",
        "                                             input_dims=(IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "# Display each image with the detected objects marked\n",
        "for path, box, cls in zip(image_paths, boxes, classes):\n",
        "    display_image_with_boxes(path, box, cls)\n",
        "\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Define function to draw boxes and labels on the image\n",
        "def draw_boxes(image_path, boxes, classes):\n",
        "    # Load image\n",
        "    image = Image.open(image_path)\n",
        "    # Define font\n",
        "    font = ImageFont.truetype(\"arial.ttf\", 12)\n",
        "    # Create drawing object\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    # Draw boxes and labels on image\n",
        "    for box, cls in zip(boxes, classes):\n",
        "        draw.rectangle(box, outline=\"red\")\n",
        "        draw.text((box[0], box[1] - 12), cls, font=font)\n",
        "    # Display image\n",
        "    image.show()\n",
        "\n",
        "# Display each image with the detected objects marked\n",
        "for path, box, cls in zip(image_paths, boxes, classes):\n",
        "    draw_boxes(path, box, cls)"
      ],
      "metadata": {
        "id": "dg5BrgNMBbE5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}